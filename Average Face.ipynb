{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blogs related to this exercise:\n",
    "\n",
    "[Average Face : OpenCV ( C++ / Python ) Tutorial](https://www.learnopencv.com/average-face-opencv-c-python-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get face landmarks\n",
    "\n",
    "def get_landmarks(filename, predictor_path = 'data/shape_predictor_68_face_landmarks.dat'):\n",
    "    \n",
    "    # Instantiate a face detector\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(predictor_path)\n",
    "    \n",
    "    img = dlib.load_rgb_image(filename)\n",
    "\n",
    "    # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "    # second argument indicates that we should upsample the image 1 time. This\n",
    "    # will make everything bigger and allow us to detect more faces.\n",
    "    detected = detector(img, 1) # Return corresponding rectangles for the detected faces\n",
    "    for index, box in enumerate(detected):\n",
    "        landmarks = predictor(img, box)  \n",
    "        coords = []\n",
    "        for i in range(0, 68):\n",
    "            coords.append((landmarks.part(i).x, landmarks.part(i).y))\n",
    "\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing similarity transform given two sets of reference points\n",
    "# OpenCV requires 3 pairs of corresponding points\n",
    "# We are faking the third one by forming a equilateral \n",
    "# triangle with the existing two points\n",
    "\n",
    "def similarity_transform(src_points, dst_points):\n",
    "    s60 = math.sin(60 * math.pi / 180)\n",
    "    c60 = math.cos(60 * math.pi / 180)\n",
    "    \n",
    "    src_points = np.copy(src_points).tolist()\n",
    "    dst_points = np.copy(dst_points).tolist()\n",
    "    \n",
    "    # Faked source reference point \n",
    "    src_x = c60 * (src_points[0][0] - src_points[1][0]) - s60 * (src_points[0][1] - src_points[1][1]) + src_points[1][0]\n",
    "    src_y = s60 * (src_points[0][0] - src_points[1][0]) + c60 * (src_points[0][1] - src_points[1][1]) + src_points[1][1]\n",
    "    \n",
    "    src_points.append([np.int(src_x), np.int(src_y)])\n",
    "    \n",
    "    # Faked destination reference point\n",
    "    dst_x = c60 * (dst_points[0][0] - dst_points[1][0]) - s60 * (dst_points[0][1] - dst_points[1][1]) + dst_points[1][0]\n",
    "    dst_y = s60 * (dst_points[0][0] - dst_points[1][0]) + c60 * (dst_points[0][1] - dst_points[1][1]) + dst_points[1][1]\n",
    "    \n",
    "    dst_points.append([np.int(dst_x), np.int(dst_y)])\n",
    "    \n",
    "    # Get the corresponding rigid transform matrix\n",
    "    transform_mat = cv2.estimateRigidTransform(np.array(src_points), np.array(dst_points), False)\n",
    "    \n",
    "    return transform_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a point is inside of a rectangle, this is a must for `Subdiv2D`\n",
    "def is_inside(rect, point):\n",
    "    if point[0] < rect[0]:\n",
    "        return False\n",
    "    if point[1] < rect[1]:\n",
    "        return False\n",
    "    if point[0] > rect[2]:\n",
    "        return False\n",
    "    if point[1] > rect[3]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Calculate Delaunay triangles\n",
    "def calculate_delaunay_triangles(rect, points):\n",
    "    # Create subdivisions\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "    \n",
    "    # Insert points into subdiv\n",
    "    for p in points:\n",
    "        subdiv.insert((p[0], p[1]))\n",
    "    \n",
    "    # List of possible triangles can be formed by above points\n",
    "    triangles = subdiv.getTriangleList()\n",
    "    print(\"Totally there are {} triangles generated\".format(len(triangles)))\n",
    "    \n",
    "    # Find the vertex indicies of triangles in the points array\n",
    "    delaunay_triangles = []\n",
    "    \n",
    "    for t in triangles:\n",
    "        pts = []\n",
    "        pts.append((t[0], t[1]))\n",
    "        pts.append((t[2], t[3]))\n",
    "        pts.append((t[4], t[5]))\n",
    "        \n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])\n",
    "        \n",
    "        if is_inside(rect, pt1) and is_inside(rect, pt2) and is_inside(rect, pt3):\n",
    "            indicies = []\n",
    "            for i in range(0, 3):\n",
    "                for j in range(0, len(points)):\n",
    "                    if abs(pts[i][0] - points[j][0]) < 1.0 and abs(pts[i][1] - points[j][1]) < 1.0:\n",
    "                        indicies.append(j)\n",
    "            if len(indicies) == 3:\n",
    "                delaunay_triangles.append((indicies[0], indicies[1], indicies[2]))\n",
    "    print(\"Totally there are {} Delaunay triangles\".format(len(delaunay_triangles)))\n",
    "    \n",
    "    return delaunay_triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply affine transform calculated using src_ri and dst_ri to src and output an image of certain size\n",
    "def apply_affine_transform(src, src_tri, dst_tri, size):\n",
    "    # Given a pair of triangles, find the affine transform needed\n",
    "    warp_mat = cv2.getAffineTransform(np.float32(src_tri), np.float32(dst_tri))\n",
    "    \n",
    "    # Apply the above Affine transform to the src image\n",
    "    dst = cv2.warpAffine(src, warp_mat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "    \n",
    "    return dst\n",
    "    \n",
    "\n",
    "def warp_triangle(img1, img2, t1, t2):\n",
    "    # In openCV, affine is applied to rectangle images but not triangle regions\n",
    "    # Find bounding rectangle for each triangle\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "    \n",
    "    # Offset points by left top corner of the respective rectangles\n",
    "    t1_rect = []\n",
    "    t2_rect = []\n",
    "    t2_rect_int = []\n",
    "    \n",
    "    for i in range(0, 3):\n",
    "        t1_rect.append(((t1[i][0] - r1[0]), (t1[i][1] - r1[1])))\n",
    "        t2_rect.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
    "        t2_rect_int.append(((t2[i][0] - r2[0]), (t2[i][0] - r2[1])))\n",
    "        \n",
    "    # Get a mask by filling the triangle\n",
    "    mask = np.zeros((r2[3], r2[2], 3), dtype=np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(t2_rect_int), (1.0, 1.0, 1.0), 16, 0)\n",
    "    \n",
    "    # Apply warp to a small rectanglar area of the image\n",
    "    img1_rect = img1[r1[1]: r1[1]+r1[3], r1[0]: r1[0]+r1[2]]\n",
    "    \n",
    "    # Desired image size for the rectanglar area\n",
    "    size = (r2[2], r2[3])\n",
    "    \n",
    "    img2_rect = apply_affine_transform(img1_rect, t1_rect, t2_rect, size)\n",
    "    img2_rect = img2_rect * mask\n",
    "    \n",
    "    img2[r2[1]: r2[1]+r2[3], r2[0]: r2[0]+r2[2]] = img2[r2[1]: r2[1]+r2[3], r2[0]: r2[0]+r2[2]] * ((1.0, 1.0, 1.0) - mask)\n",
    "    img2[r2[1]: r2[1]+r2[3], r2[0]: r2[0]+r2[2]] = img2[r2[1]: r2[1]+r2[3], r2[0]: r2[0]+r2[2]] + img2_rect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'images/presidents'\n",
    "\n",
    "facial_images = []\n",
    "facial_landmarks = []\n",
    "\n",
    "for file in glob('images/presidents/*'):\n",
    "    if file.endswith('.jpg'):\n",
    "        # Read in images one by one and convert them to float\n",
    "        img = np.float32(cv2.imread(file)) / 255.0\n",
    "        facial_images.append(img)\n",
    "        # For each face, detect landmarks\n",
    "        facial_landmarks.append(get_landmarks(file))\n",
    "        \n",
    "num_images = len(facial_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup target image size and reference points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width and height dimensions of the output image\n",
    "w, h = 600, 600\n",
    "\n",
    "# Destination eye corner positions in the output image\n",
    "eye_corners_dst = [(np.int(0.3*w), np.int(h/3)), (np.int(0.7*w), np.int(h/3))]\n",
    "\n",
    "# Add 8 boundary points for Delaunay triangulation\n",
    "boundary_landmarks = np.array([(0, 0), (w/2, 0), (w-1, 0), (w-1, h/2), (w-1, h-1), (w/2, h-1), (0, h-1), (0, h/2)])\n",
    "\n",
    "# Initializing the averaged landmarks for later computation, 68 + 8 points\n",
    "averaged_landmarks = np.array([(0, 0)] * (len(facial_landmarks[0]) + len(boundary_landmarks)), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp images and transform landmarks to the desired output coordinate system\n",
    "# and find the average of the transformed landmarks\n",
    "\n",
    "# To store the transformed faces and points according to desired similarity transform\n",
    "transformed_faces = []\n",
    "transformed_points = []\n",
    "\n",
    "for i in range(0, num_images):\n",
    "    landmarks = facial_landmarks[i]\n",
    "    \n",
    "    # Source eye corner positions of in the orginal image\n",
    "    eye_corners_src = [landmarks[36], landmarks[45]]\n",
    "    \n",
    "    # Get the similarity transform matrix\n",
    "    sim_mat = similarity_transform(eye_corners_src, eye_corners_dst)\n",
    "    \n",
    "    # Apply similarity transform to the face image\n",
    "    transformed_face = cv2.warpAffine(facial_images[i], sim_mat, (w, h))\n",
    "    \n",
    "    # Apply similarity transform on landmarks\n",
    "    transformed_landmarks = cv2.transform(np.array(landmarks).reshape((68, 1, 2)), sim_mat).reshape(68, 2)\n",
    "    \n",
    "    # Append boundary landmarks to be used for Delaunay trigangulation\n",
    "    transformed_landmarks = np.append(np.float32(transformed_landmarks), boundary_landmarks, axis=0)\n",
    "    \n",
    "    # Compute the averaged landmarks\n",
    "    averaged_landmarks += transformed_landmarks / num_images\n",
    "    \n",
    "    transformed_points.append(transformed_landmarks)\n",
    "    transformed_faces.append(transformed_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally there are 154 triangles generated\n",
      "Totally there are 142 Delaunay triangles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we naively average out all the faces, the final result will be a blury one\n",
    "# We need to use the Delaunay triangles generated from the averaged landmarks\n",
    "# as the reference to warp out each transformed faces by virtue of their Delaunay triangles\n",
    "rect = (0, 0, w, h)\n",
    "delaunay_triangles = calculate_delaunay_triangles(rect, averaged_landmarks)\n",
    "\n",
    "final_output = np.zeros((h, w, 3), np.float32)\n",
    "\n",
    "# Warp each image according to averaged image landmarks\n",
    "for i in range(0, len(transformed_faces)):\n",
    "    img = np.zeros((h, w, 3), np.float32)\n",
    "    # Warp triangles one by one\n",
    "    for j in range(0, len(delaunay_triangles)):\n",
    "        src_triangle = []\n",
    "        dst_triangle = []\n",
    "        \n",
    "        for k in range(0, 3):\n",
    "            src_point = transformed_points[i][delaunay_triangles[j][k]]\n",
    "            dst_point = averaged_landmarks[delaunay_triangles[j][k]]\n",
    "            # Here I intentionally left out the constraint point function to see what will be different\n",
    "            src_triangle.append(src_point)\n",
    "            dst_triangle.append(dst_point)\n",
    "        \n",
    "        warp_triangle(transformed_faces[i], img, src_triangle, dst_triangle)\n",
    "        \n",
    "    final_output = final_output + img\n",
    "\n",
    "final_output = final_output / num_images\n",
    "\n",
    "cv2.imshow(\"Averaged faces\", final_output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
