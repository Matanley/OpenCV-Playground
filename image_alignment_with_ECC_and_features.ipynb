{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blogs related to this exercise:\n",
    "\n",
    "[Image Alignment (ECC) in OpenCV](https://www.learnopencv.com/image-alignment-ecc-in-opencv-c-python/)\n",
    "\n",
    "[Image Alignment (Feature Based) using OpenCV](https://www.learnopencv.com/image-alignment-feature-based-using-opencv-c-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image alignment with Enhanced Correlation Coefficient Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read in the images to be aligned\n",
    "img1 = cv2.imread(\"images/image1.jpg\")\n",
    "img2 = cv2.imread(\"images/image2.jpg\")\n",
    "\n",
    "# Convert images to grayscale\n",
    "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "#print(img2_gray.shape)\n",
    "\n",
    "# Fine the size of image1\n",
    "size = img1.shape\n",
    "\n",
    "# Define the motion mode\n",
    "warp_mode = cv2.MOTION_TRANSLATION\n",
    "\n",
    "# Define 2x3 or 3x3 matrices and initialize the matrices to indentity\n",
    "# A 2x3 matrix corresponding to Affine transformation\n",
    "# A 3x3 matrix corresponding to Homography transformation\n",
    "if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "    warp_matrix = np.eye(3, 3, dtype=np.float32) # Has to be a float matrix\n",
    "else:\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32) # Has to be a float matrix\n",
    "\n",
    "# Specify the number of iterations\n",
    "number_of_iterations = 5000\n",
    "# Specify the threshold of the increment in the correlation coefficient between two iterations\n",
    "termination_eps = 1e-10\n",
    "\n",
    "# Define termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_COUNT | cv2.TERM_CRITERIA_EPS, number_of_iterations, termination_eps)\n",
    "\n",
    "# Run the ecc algorithm, the desired warp parameters are stored in warp_matrix\n",
    "retval, warp_matrix= cv2.findTransformECC(img1_gray, img2_gray, warp_matrix, warp_mode, criteria)\n",
    "\n",
    "if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "    # Use warpPerspective for Homography\n",
    "    img2_aligned = cv2.warpPerspective(img2, warp_matrix, (size[1], size[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "else:\n",
    "    # Use warpAffine for Translation, Euclidean and Affine\n",
    "    img2_aligned = cv2.warpAffine(img2, warp_matrix, (size[1], size[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "# Show final results\n",
    "cv2.imshow(\"Image 1\", img1)\n",
    "cv2.imshow(\"Image 2\", img2)\n",
    "cv2.imshow(\"Aligned Image2\", img2_aligned)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel-wise alignment utilizing gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1941, 750)\n",
      "[[  1.03404832e+00   2.44795810e-03  -2.74030662e+00]\n",
      " [  1.44800860e-02   1.02576125e+00  -5.16192245e+00]\n",
      " [  4.44452198e-05   5.57811109e-06   1.00000000e+00]]\n",
      "[[  1.01441336e+00   5.32015401e-04  -6.62373006e-01]\n",
      " [  7.65844947e-03   1.00793850e+00   2.53184557e+00]\n",
      " [  1.95356297e-05   2.78898278e-06   1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_gradient(img):\n",
    "    # Calculate the x and y gradients using Sobel operator\n",
    "    # cv2_35F corresponding with destination depth of 5\n",
    "    grad_x = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3) \n",
    "    grad_y = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    # Combine the two gradients\n",
    "    grad = cv2.addWeighted(np.absolute(grad_x), 0.5, np.absolute(grad_y), 0.5, 0)\n",
    "    return grad\n",
    "\n",
    "# Read 8-bit color image\n",
    "# This is an image in which the three channels are concatenate vertically\n",
    "\n",
    "img = cv2.imread(\"images/girls.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Find the width and height of the color image\n",
    "size = img.shape\n",
    "print(size)\n",
    "height = size[0] // 3\n",
    "width = size[1]\n",
    "\n",
    "# Extract the three channels from the gray scale image\n",
    "# and merge the three channels into one color image\n",
    "img_colored = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "for i in range(0, 3):\n",
    "    img_colored[:, :, i] = img[i*height: (i+1)*height, :]\n",
    "\n",
    "# Allocate space for aligned image\n",
    "img_aligned = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "# The blue and green channels will be aligned to the red channel\n",
    "# so the red channel are copied as is\n",
    "img_aligned[:, :, 2] = img_colored[:, :, 2]\n",
    "\n",
    "# Define motion model\n",
    "warp_mode = cv2.MOTION_HOMOGRAPHY\n",
    "\n",
    "# Set the warp matrix to identity\n",
    "if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "    warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "else:\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.folat32)\n",
    "    \n",
    "# Set the stopping criteria for the algorithm\n",
    "criteria = (cv2.TERM_CRITERIA_COUNT | cv2.TERM_CRITERIA_EPS, 5000, 1e-10)\n",
    "\n",
    "# Warp the blue and green channels to the red channel\n",
    "for i in range(0, 2):\n",
    "    # The three channels are not strongly correlated, so you need the gradient instead\n",
    "    retval, warp_matrix = cv2.findTransformECC(get_gradient(img_colored[:, :, 2]), get_gradient(img_colored[:, :, i]), warp_matrix, warp_mode, criteria)\n",
    "    \n",
    "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "        # Use warpPerspective when transformation is homography\n",
    "        img_aligned[:, :, i] = cv2.warpPerspective(img_colored[:, :, i], warp_matrix, (width, height), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "    else:\n",
    "        # Use warpAffine when transformation is not homography\n",
    "        img_aligned[:, :, i] = cv2.warpAffine(img_colored[:, :, i], warp_matrix, (width, height), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "    print(warp_matrix)   \n",
    "\n",
    "# Show final output\n",
    "cv2.imshow(\"Color Image\", img_colored)\n",
    "cv2.imshow(\"Aligned Image\", img_aligned)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<figure>\n",
    "  <img src = \"images/girls-aligned.jpg\" width = \"100%\" style = \"border: thin silver solid; padding: 1px\">\n",
    "      <figcaption style = \"text-align:left; font-style:italic\">Image alignment using color channels' gradient</figcaption>\n",
    "</figure> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature based image alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading reference image: images/form.jpg\n",
      "Reading image to be aligned: images/scanned-form.jpg\n",
      "Aligning Images ...\n",
      "75\n",
      "Saving aligned image: images/aligned.jpg\n",
      "Estimated homography:\n",
      " [[  1.38140525e+00  -2.03885205e-01  -5.41252115e+00]\n",
      " [  2.17958789e-01   1.49648830e+00  -4.73234516e+02]\n",
      " [ -7.16127408e-05   1.04388020e-04   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "MAX_MATCHES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n",
    "\n",
    "def align_images(img1, img2):\n",
    "    \n",
    "    # Convert images to grayscale\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect ORB features and compute descriptors\n",
    "    orb = cv2.ORB_create(MAX_MATCHES)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(img1_gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(img2_gray, None)\n",
    "    \n",
    "    # Match features\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "    matches = matcher.match(descriptors1, descriptors2, None)\n",
    "    \n",
    "    # Sort matches by score\n",
    "    matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "    \n",
    "    # Remove matches that are not good enough\n",
    "    num_good_matches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "    matches = matches[:num_good_matches]\n",
    "    \n",
    "    # Draw top matches\n",
    "    img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches, None)\n",
    "    cv2.imwrite(\"matches.jpg\", img_matches)\n",
    "    \n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    \n",
    "    for i, match in enumerate(matches):\n",
    "        # Here the 'queryIdx' and 'trainIdx' is really elusive to me\n",
    "        # https://stackoverflow.com/questions/10765066/what-is-query-and-train-in-opencv-features2d\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "        \n",
    "    # Find homography\n",
    "    h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "    \n",
    "    # Use homography\n",
    "    height, width, channels = img2.shape\n",
    "    img1_aligned = cv2.warpPerspective(img1, h, (width, height))\n",
    "    \n",
    "    return img1_aligned, h\n",
    "\n",
    "    \n",
    "# Read in the reference image\n",
    "reference_name = 'images/form.jpg'\n",
    "print(\"Reading reference image:\", reference_name)\n",
    "reference_img = cv2.imread(reference_name, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Read in image to be aligned\n",
    "tilted_name = \"images/scanned-form.jpg\"\n",
    "print(\"Reading image to be aligned:\", tilted_name)\n",
    "tilted_img = cv2.imread(tilted_name, cv2.IMREAD_COLOR)\n",
    "\n",
    "print(\"Aligning Images ...\")\n",
    "# Aligned image will be stored in aligned\n",
    "aligned, h = align_images(tilted_img, reference_img)\n",
    "\n",
    "# Write aligned image to disk\n",
    "out_filename = 'images/aligned.jpg'\n",
    "print(\"Saving aligned image:\", out_filename)\n",
    "cv2.imwrite(out_filename, aligned)\n",
    "\n",
    "# Print estimated homography\n",
    "print(\"Estimated homography:\\n\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<figure>\n",
    "  <img src = \"images/image-alignment-using-opencv.jpg\" width = \"100%\" style = \"border: thin silver solid; padding: 1px\">\n",
    "      <figcaption style = \"text-align:left; font-style:italic\">Image alignment with features</figcaption>\n",
    "</figure> \n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
